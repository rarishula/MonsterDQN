class GameEnvironment(gym.Env):
    def __init__(self):
        # プレイヤーとAIの初期モンスターを設定
        self.initial_player_monsters = [("Grass", 6), ("Fire", 6), ("Water", 6)]
        self.initial_ai_monsters = [("Grass", 6), ("Fire", 6), ("Water", 6)]

        # 状態スペースのサイズを設定（プレイヤーとAIのモンスターを合わせた数）
        self.state_size = len(self.initial_player_monsters) * 2  # 各モンスターは2つの属性（タイプとHP）を持つ

        # アクションスペースを設定（交替と攻撃の選択肢）
        self.action_space = gym.spaces.Discrete(4)  # 4つの行動（2種類の攻撃と2種類の交替）   def random_action(self, player_monsters):
        valid_actions = get_valid_actions(player_monsters)

        # 各行動を同様に確からしいとする
        action_probability = 1.0 / len(valid_actions) if valid_actions else 0
        return [(action, action_probability) for action in valid_actions]
        
    def reset(self):
        # モンスターの初期状態をコピー
        self.player_monsters = deepcopy(self.initial_player_monsters)
        self.ai_monsters = deepcopy(self.initial_ai_monsters)
    
        # stateを再計算
        self.state = self._convert_to_state(self.player_monsters, self.ai_monsters)
    
        return self.state
        
    def render(self, mode='human'):
        # 現在の状態をテキストで表示する
        print("現在の状態:")
        print("プレイヤーのモンスター:", self.player_monsters)
        print("AIのモンスター:", self.ai_monsters)

    

        
    def _convert_to_state(self, player_monsters, ai_monsters):
        state = []
        for monster in player_monsters + ai_monsters:
            # モンスターの特徴を追加
            state.append(self._convert_monster_to_features(monster))
        return state
    
    def _convert_monster_to_features(self, monster):
        # モンスターのタイプを数値に変換
        type_to_number = {"Grass": 0, "Fire": 1, "Water": 2}
        type_num = type_to_number[monster[0]]
    
        # モンスターの体力
        hp = monster[1]
    
        return [type_num, hp]
                
    def calculate_next_states_and_probabilities(self, ai_action):
        player_monsters, ai_monsters = deepcopy(self.player_monsters , self.ai_monsters)

        # プレイヤーの合法手と選択確率を取得
        player_actions_with_select_probs = self.random_action(player_monsters)
        
        # 合法手とAIの行動から行動組み合わせと選択確率を作成
        action_combinations_with_select_probs = [(player_action, ai_action, select_prob) for player_action, select_prob in player_actions_with_select_probs]

        next_states_and_probs = []
        for player_action, ai_action, select_prob in action_combinations_with_select_probs:
            action_order = determine_action_order(player_action, ai_action)

            # 攻撃が一つ以下の場合の処理
            if sum(action in ["special_attack", "normal_attack"] for _, action in action_order) <= 1:
                temp_player_monsters, temp_ai_monsters = self.apply_actions(player_monsters, ai_monsters, action_order)
                next_states_and_probs.append(((temp_player_monsters, temp_ai_monsters), select_prob))

            # 攻撃が二つある場合の処理
            elif sum(action in ["special_attack", "normal_attack"] for _, action in action_order) == 2:
                # シナリオ1: プレイヤー先攻
                temp_player_monsters, temp_ai_monsters = self.apply_actions(player_monsters, ai_monsters, action_order)
                next_states_and_probs.append(((temp_player_monsters, temp_ai_monsters), select_prob * 0.5))

                # シナリオ2: AI先攻
                player_monsters, ai_monsters = deepcopy(state)  # 状態をリセット
                action_order.reverse()
                temp_player_monsters, temp_ai_monsters = self.apply_actions(player_monsters, ai_monsters, action_order)
                next_states_and_probs.append(((temp_player_monsters, temp_ai_monsters), select_prob * 0.5))

        return next_states_and_probs
        
    def apply_actions(self, player_monsters, ai_monsters, action_order):
        # 与えられた行動順序に従って行動を適用
        temp_player_monsters, temp_ai_monsters = deepcopy(player_monsters), deepcopy(ai_monsters)
        for side, action in action_order:
            if action.startswith("switch"):
                process_switch(side, action, temp_player_monsters, temp_ai_monsters)
            elif action in ["special_attack", "normal_attack"]:
                if side == "player":
                    temp_player_monsters, temp_ai_monsters, _ = calculate_and_apply_damage(temp_player_monsters, temp_ai_monsters, action)
                else:
                    temp_ai_monsters, temp_player_monsters, _ = calculate_and_apply_damage(temp_ai_monsters, temp_player_monsters, action)
        return temp_player_monsters, temp_ai_monsters
        


    def select_randomly_based_on_probability(next_states_and_probs):
        total_prob = sum(prob for _, prob in next_states_and_probs)
        rand_prob = random.uniform(0, total_prob)
        cumulative_prob = 0
    
        for next_state, prob in next_states_and_probs:
            cumulative_prob += prob
            if cumulative_prob >= rand_prob:
                return next_state
    
        return next_states_and_probs[-1][0]  # 万が一の場合、最後の要素を返す
        
    def calculate_reward(self, next_state):
        # 定数の設定
        WIN_REWARD = 100
        LOSE_REWARD = -100
        DAMAGE_REWARD_FACTOR = 50
    
        player_monsters, ai_monsters = self.player_monsters , self.ai_monsters
        next_player_monsters, next_ai_monsters = next_state
    
        # 1. 勝敗報酬
        if all(hp <= 0 for _, hp in next_ai_monsters):
            return WIN_REWARD  # 勝利
        elif all(hp <= 0 for _, hp in next_player_monsters):
            return LOSE_REWARD  # 敗北
    
        # 2. ダメージ報酬
        damage_reward = DAMAGE_REWARD_FACTOR * (
            sum(hp for _, hp in player_monsters) - sum(hp for _, hp in next_player_monsters)
        )
        damage_taken_reward = DAMAGE_REWARD_FACTOR * (
            sum(hp for _, hp in ai_monsters) - sum(hp for _, hp in next_ai_monsters)
        )
    
        # 3. 対面報酬
        front_monster_advantage_reward = 0
        if is_advantageous(next_player_monsters[0], next_ai_monsters[0]):
            front_monster_advantage_reward += 10
        elif is_advantageous(next_ai_monsters[0], next_player_monsters[0]):
            front_monster_advantage_reward -= 10
    
        return damage_reward - damage_taken_reward + front_monster_advantage_reward
        
    def step(self, action):
        # 次の状態と報酬を計算する
        next_states_and_probs = self.calculate_next_states_and_probabilities(action)
        next_state = self.select_randomly_based_on_probability(next_states_and_probs)
        reward = self.calculate_reward(next_state)

        return next_state, reward
        
    def is_done(next_state):
        # 次の状態のモンスターの状態を取得
        next_player_monsters, next_ai_monsters = next_state
    
        # プレイヤーのモンスターが全て倒されたかどうか
        player_all_fainted = all(hp <= 0 for _, hp in next_player_monsters)
    
        # AIのモンスターが全て倒されたかどうか
        ai_all_fainted = all(hp <= 0 for _, hp in next_ai_monsters)
    
        # どちらかが全て倒された場合、ゲーム終了
        return player_all_fainted or ai_all_fainted
        
def is_advantageous(monster1, monster2):
    # モンスター間の有利不利を判断する関数
    # monster1とmonster2はそれぞれモンスターのタイプを表す文字列

    advantage_dict = {
        "Grass": "Water",
        "Water": "Fire",
        "Fire": "Grass"
    }

    if advantage_dict[monster1[0]] == monster2[0]:
        return True  # monster1はmonster2に対して有利
    else:
        return False  # monster1はmonster2に対して不利